{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab Two-Stage Runner (Severstal -> NEU)\n",
    "Run top-to-bottom once. After disconnect, rerun only unfinished cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import sys, subprocess\n",
    "\n",
    "# Reinstall a compatible scientific stack\n",
    "subprocess.check_call([\n",
    "    sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"--force-reinstall\",\n",
    "    \"numpy==1.26.4\",\n",
    "    \"scipy==1.11.4\",\n",
    "    \"scikit-learn==1.4.2\",\n",
    "    \"pandas==2.2.2\",\n",
    "    \"matplotlib==3.8.4\",\n",
    "    \"pillow==10.3.0\",\n",
    "    \"pyyaml==6.0.1\",\n",
    "    \"tqdm==4.66.4\",\n",
    "])\n",
    "\n",
    "print(\"Done. Now restart runtime: Runtime > Restart runtime\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "repo = Path('/content/FYP-code')\n",
    "if repo.exists():\n",
    "    print('Repo exists, pulling latest...')\n",
    "    subprocess.check_call(['git', '-C', str(repo), 'pull', '--ff-only'])\n",
    "else:\n",
    "    print('Cloning repo...')\n",
    "    subprocess.check_call(['git', 'clone', 'https://github.com/spinelessknave8/FYP_code.git', str(repo)])\n",
    "\n",
    "os.chdir(repo)\n",
    "print('cwd:', os.getcwd())\n",
    "subprocess.check_call(['git', '-C', str(repo), 'log', '-1', '--oneline'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print('torch:', torch.__version__)\n",
    "print('cuda available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('gpu:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Prefer explicit paths to avoid discovery failures.\n",
    "sev = Path('/content/drive/MyDrive/datasets/severstal')\n",
    "neu = Path('/content/drive/MyDrive/datasets/neu')\n",
    "\n",
    "print('severstal:', sev, sev.exists())\n",
    "print('neu:', neu, neu.exists())\n",
    "\n",
    "if not sev.exists() or not neu.exists():\n",
    "    raise RuntimeError('Dataset paths not found under /content/drive/MyDrive/datasets')\n",
    "\n",
    "base = yaml.safe_load(Path('configs/default.yaml').read_text())\n",
    "base['device'] = 'cuda'\n",
    "base['severstal']['data_root'] = str(sev)\n",
    "base['severstal']['train_csv'] = 'train.csv'\n",
    "base['severstal']['images_dir'] = 'train_images'\n",
    "base['neu']['data_root'] = str(neu)\n",
    "base['output_dir'] = '/content/drive/MyDrive/fyp_outputs'\n",
    "\n",
    "Path('configs/default.colab.yaml').write_text(yaml.safe_dump(base, sort_keys=False))\n",
    "print('wrote configs/default.colab.yaml')\n",
    "\n",
    "for s in ['a', 'b', 'c']:\n",
    "    split_cfg = yaml.safe_load(Path(f'configs/neu_split_{s}.yaml').read_text())\n",
    "    merged = yaml.safe_load(yaml.safe_dump(base))\n",
    "    merged.update(split_cfg)\n",
    "    out = Path(f'configs/neu_split_{s}.colab.yaml')\n",
    "    out.write_text(yaml.safe_dump(merged, sort_keys=False))\n",
    "    print('wrote', out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "cfg = yaml.safe_load(Path('configs/default.colab.yaml').read_text())\n",
    "assert Path(cfg['severstal']['data_root']).exists(), cfg['severstal']['data_root']\n",
    "assert Path(cfg['neu']['data_root']).exists(), cfg['neu']['data_root']\n",
    "assert (Path(cfg['severstal']['data_root']) / 'train.csv').exists(), 'Missing train.csv'\n",
    "assert (Path(cfg['severstal']['data_root']) / 'train_images').exists(), 'Missing train_images'\n",
    "print('sanity checks passed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from src.pipelines.notebook_entrypoints import run_two_stage_stage1\n",
    "\n",
    "# Stage 1 runs once; it reuses existing memory/val artifacts if already present.\n",
    "t = time.time()\n",
    "run_two_stage_stage1('configs/default.colab.yaml')\n",
    "print(f'stage 1 done in {time.time()-t:.1f}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from src.pipelines.notebook_entrypoints import run_split_pipeline\n",
    "\n",
    "t = time.time()\n",
    "run_split_pipeline('configs/neu_split_a.colab.yaml', skip_if_complete=True)\n",
    "print(f'split A done in {time.time()-t:.1f}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from src.pipelines.notebook_entrypoints import run_split_pipeline\n",
    "\n",
    "t = time.time()\n",
    "run_split_pipeline('configs/neu_split_b.colab.yaml', skip_if_complete=True)\n",
    "print(f'split B done in {time.time()-t:.1f}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from src.pipelines.notebook_entrypoints import run_split_pipeline\n",
    "\n",
    "t = time.time()\n",
    "run_split_pipeline('configs/neu_split_c.colab.yaml', skip_if_complete=True)\n",
    "print(f'split C done in {time.time()-t:.1f}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base = Path('/content/drive/MyDrive/fyp_outputs')\n",
    "for s in ['split_a', 'split_b', 'split_c']:\n",
    "    print(\n",
    "        s,\n",
    "        'osr:', (base / s / 'osr' / 'metrics.json').exists(),\n",
    "        'cascade:', (base / s / 'cascade' / 'metrics.json').exists(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys\n",
    "\n",
    "base = '/content/drive/MyDrive/fyp_outputs'\n",
    "subprocess.check_call([sys.executable, '-m', 'src.pipelines.aggregate_osr', '--output_dir', base])\n",
    "subprocess.check_call([\n",
    "    sys.executable,\n",
    "    '-m',\n",
    "    'src.pipelines.plot_combined_osr',\n",
    "    '--output_dir', base,\n",
    "    '--out_dir', f'{base}/combined',\n",
    "])\n",
    "print('aggregate + combined plots done')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}