{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Stage OSR Runner (Browser Colab)\n",
    "\n",
    "Clean flow: mount drive -> clone/pull repo -> install deps -> discover dataset paths -> run stage1 + splits -> summarize metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess\n",
    "print('python:', sys.executable)\n",
    "print('cwd:', os.getcwd())\n",
    "try:\n",
    "    subprocess.run(['nvidia-smi'], check=False)\n",
    "except FileNotFoundError:\n",
    "    print('nvidia-smi not found in PATH (this can happen in some runtimes).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, subprocess\n",
    "\n",
    "REPO_URL = 'https://github.com/spinelessknave8/FYP_code.git'\n",
    "REPO_DIR = Path('/content/FYP-code')\n",
    "\n",
    "if not REPO_DIR.exists():\n",
    "    subprocess.check_call(['git', 'clone', REPO_URL, str(REPO_DIR)])\n",
    "else:\n",
    "    subprocess.run(['git', '-C', str(REPO_DIR), 'pull'], check=False)\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "print('repo root:', Path.cwd())\n",
    "print('default.yaml exists:', Path('configs/default.yaml').exists())\n",
    "print('src exists:', Path('src').exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-r', 'requirements.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print('torch:', torch.__version__)\n",
    "print('cuda available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('gpu:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('WARNING: CUDA not available; check runtime type and torch build.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "sev = neu = None\n",
    "search_roots = [\n",
    "    Path('/content/drive/MyDrive'),\n",
    "    Path('/content/drive/Shareddrives'),\n",
    "    Path('/content/drive/.shortcut-targets-by-id'),\n",
    "]\n",
    "\n",
    "sev_hits, neu_hits = [], []\n",
    "for root in search_roots:\n",
    "    if not root.exists():\n",
    "        continue\n",
    "    sev_hits.extend([p for p in root.glob('**/severstal') if p.is_dir()])\n",
    "    neu_hits.extend([p for p in root.glob('**/neu') if p.is_dir()])\n",
    "\n",
    "if sev_hits and neu_hits:\n",
    "    sev, neu = sev_hits[0], neu_hits[0]\n",
    "\n",
    "print('severstal path:', sev)\n",
    "print('neu path:', neu)\n",
    "\n",
    "if sev is None or neu is None:\n",
    "    raise RuntimeError('Could not find severstal/neu under mounted drive. Add shortcuts in MyDrive or set explicit paths.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from src.pipelines.notebook_entrypoints import run_two_stage_stage1, run_split_pipeline\n",
    "\n",
    "assert sev is not None and neu is not None, 'Run dataset discovery cell first.'\n",
    "\n",
    "t_all = time.time()\n",
    "print('[0/6] Building Colab configs...')\n",
    "\n",
    "base = yaml.safe_load(Path('configs/default.yaml').read_text())\n",
    "base['device'] = 'cuda'\n",
    "base['severstal']['data_root'] = str(sev)\n",
    "base['severstal']['train_csv'] = 'train.csv'\n",
    "base['severstal']['images_dir'] = 'train_images'\n",
    "base['neu']['data_root'] = str(neu)\n",
    "base['output_dir'] = '/content/drive/MyDrive/fyp_outputs'\n",
    "\n",
    "Path('configs/default.colab.yaml').write_text(yaml.safe_dump(base, sort_keys=False))\n",
    "print('  wrote configs/default.colab.yaml')\n",
    "\n",
    "split_colab = []\n",
    "for s in ['a', 'b', 'c']:\n",
    "    split_cfg = yaml.safe_load(Path(f'configs/neu_split_{s}.yaml').read_text())\n",
    "    merged = yaml.safe_load(yaml.safe_dump(base))\n",
    "    merged.update(split_cfg)\n",
    "    out = Path(f'configs/neu_split_{s}.colab.yaml')\n",
    "    out.write_text(yaml.safe_dump(merged, sort_keys=False))\n",
    "    split_colab.append(str(out))\n",
    "    print('  wrote', out)\n",
    "\n",
    "print('[1/6] Sanity checks...')\n",
    "assert Path(base['severstal']['data_root']).exists(), base['severstal']['data_root']\n",
    "assert Path(base['neu']['data_root']).exists(), base['neu']['data_root']\n",
    "print('  sanity checks passed')\n",
    "\n",
    "print('[2/6] Stage 1: PatchCore')\n",
    "t = time.time()\n",
    "run_two_stage_stage1('configs/default.colab.yaml')\n",
    "print(f'  stage 1 done in {time.time() - t:.1f}s')\n",
    "\n",
    "for i, split in enumerate(split_colab, start=3):\n",
    "    print(f'[{i}/6] Split pipeline: {split}')\n",
    "    t = time.time()\n",
    "    run_split_pipeline(split)\n",
    "    print(f'  {split} done in {time.time() - t:.1f}s')\n",
    "\n",
    "print(f'[6/6] All done in {time.time() - t_all:.1f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from pathlib import Path\n",
    "import sys, subprocess\n",
    "\n",
    "base = Path('/content/drive/MyDrive/fyp_outputs')\n",
    "\n",
    "# quick metric summary\n",
    "for split in ['split_a', 'split_b', 'split_c']:\n",
    "    p = base / split / 'cascade' / 'metrics.json'\n",
    "    if not p.exists():\n",
    "        print(split, 'missing metrics:', p)\n",
    "        continue\n",
    "    m = json.loads(p.read_text())\n",
    "    print(split, {\n",
    "        'tpr_unknown_system': m.get('tpr_unknown_system'),\n",
    "        'fpr_known_system': m.get('fpr_known_system'),\n",
    "        'stage1_pass_rate_known': m.get('stage1_pass_rate_known'),\n",
    "        'stage1_pass_rate_unknown': m.get('stage1_pass_rate_unknown'),\n",
    "    })\n",
    "\n",
    "# aggregate + combined plots\n",
    "subprocess.check_call([sys.executable, '-m', 'src.pipelines.aggregate_osr', '--output_dir', str(base)])\n",
    "subprocess.check_call([sys.executable, '-m', 'src.pipelines.plot_combined_osr', '--output_dir', str(base), '--out_dir', str(base / 'combined')])\n",
    "\n",
    "# display core plots\n",
    "for split in ['split_a', 'split_b', 'split_c']:\n",
    "    for name in ['loss_curve.png', 'acc_curve.png', 'roc_osr.png', 'hist_osr.png']:\n",
    "        p = base / split / 'plots' / name\n",
    "        if p.exists():\n",
    "            plt.figure(figsize=(6, 3.5))\n",
    "            plt.title(f'{split} - {name}')\n",
    "            plt.imshow(mpimg.imread(p))\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "for name in ['roc_combined.png', 'mahalanobis_combined.png']:\n",
    "    p = base / 'combined' / name\n",
    "    if p.exists():\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        plt.title(name)\n",
    "        plt.imshow(mpimg.imread(p))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# stage-1 leakage/pass visuals\n",
    "rows = []\n",
    "for s in ['split_a', 'split_b', 'split_c']:\n",
    "    p = base / s / 'cascade' / 'metrics.json'\n",
    "    if not p.exists():\n",
    "        continue\n",
    "    m = json.loads(p.read_text())\n",
    "    rows.append({\n",
    "        'split': s,\n",
    "        'stage1_pass_rate_known': m.get('stage1_pass_rate_known', np.nan),\n",
    "        'stage1_pass_rate_unknown': m.get('stage1_pass_rate_unknown', np.nan),\n",
    "        'stage1_leakage_rate_known': m.get('stage1_leakage_rate_known', np.nan),\n",
    "        'stage1_leakage_rate_unknown': m.get('stage1_leakage_rate_unknown', np.nan),\n",
    "        'tpr_unknown_system': m.get('tpr_unknown_system', np.nan),\n",
    "        'fpr_known_system': m.get('fpr_known_system', np.nan),\n",
    "        'tpr_unknown_conditional': m.get('tpr_unknown_conditional', np.nan),\n",
    "        'fpr_known_conditional': m.get('fpr_known_conditional', np.nan),\n",
    "    })\n",
    "\n",
    "if rows:\n",
    "    x = np.arange(len(rows))\n",
    "    labels = [r['split'] for r in rows]\n",
    "    w = 0.35\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(x - w/2, [r['stage1_pass_rate_known'] for r in rows], width=w, label='known pass rate')\n",
    "    plt.bar(x + w/2, [r['stage1_pass_rate_unknown'] for r in rows], width=w, label='unknown pass rate')\n",
    "    plt.xticks(x, labels); plt.ylim(0,1); plt.ylabel('Rate'); plt.title('Stage-1 Pass Rates by Split'); plt.legend(); plt.grid(axis='y', alpha=0.25); plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(x - w/2, [r['stage1_leakage_rate_known'] for r in rows], width=w, label='known leakage')\n",
    "    plt.bar(x + w/2, [r['stage1_leakage_rate_unknown'] for r in rows], width=w, label='unknown leakage')\n",
    "    plt.xticks(x, labels); plt.ylim(0,1); plt.ylabel('Rate'); plt.title('Stage-1 Leakage Rates by Split'); plt.legend(); plt.grid(axis='y', alpha=0.25); plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(labels, [r['tpr_unknown_system'] for r in rows], marker='o', label='TPR unknown (system)')\n",
    "    plt.plot(labels, [r['tpr_unknown_conditional'] for r in rows], marker='o', label='TPR unknown (conditional)')\n",
    "    plt.ylim(0,1); plt.ylabel('Rate'); plt.title('Unknown Detection TPR: System vs Conditional'); plt.legend(); plt.grid(alpha=0.25); plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(labels, [r['fpr_known_system'] for r in rows], marker='o', label='FPR known (system)')\n",
    "    plt.plot(labels, [r['fpr_known_conditional'] for r in rows], marker='o', label='FPR known (conditional)')\n",
    "    plt.ylim(0,1); plt.ylabel('Rate'); plt.title('Known Rejection FPR: System vs Conditional'); plt.legend(); plt.grid(alpha=0.25); plt.show()\n",
    "\n",
    "    print('Split-wise cascade summary:')\n",
    "    for r in rows:\n",
    "        print(r['split'], {\n",
    "            'pass_known': round(r['stage1_pass_rate_known'], 4),\n",
    "            'pass_unknown': round(r['stage1_pass_rate_unknown'], 4),\n",
    "            'leak_known': round(r['stage1_leakage_rate_known'], 4),\n",
    "            'leak_unknown': round(r['stage1_leakage_rate_unknown'], 4),\n",
    "            'tpr_sys': round(r['tpr_unknown_system'], 4),\n",
    "            'fpr_sys': round(r['fpr_known_system'], 4),\n",
    "        })\n",
    "else:\n",
    "    print('No cascade metrics found for leakage/pass visualizations.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}