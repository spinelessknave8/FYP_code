{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Stage OSR Runner (Colab / VS Code Colab Kernel)\n",
    "\n",
    "This notebook runs the current repo pipelines directly:\n",
    "- Stage 1: `src.pipelines.two_stage.train_patchcore`\n",
    "- Stage 2 prep: `train_classifier -> extract_embeddings -> run_osr`\n",
    "- Cascade: `run_cascade`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess\n",
    "print('python:', sys.executable)\n",
    "print('cwd:', os.getcwd())\n",
    "subprocess.run(['nvidia-smi'], check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: mount Google Drive when running on Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print('Drive mounted at /content/drive')\n",
    "except Exception as e:\n",
    "    print('Drive mount skipped:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# If repo is not already present, set this URL and run this cell again.\n",
    "REPO_URL = ''  # e.g. https://github.com/<user>/<repo>.git\n",
    "REPO_DIR = Path('/content/FYP-code')\n",
    "\n",
    "def find_repo_root():\n",
    "    candidates = [\n",
    "        Path.cwd(),\n",
    "        REPO_DIR,\n",
    "        Path('/content/drive/MyDrive/FYP-code'),\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if (p / 'configs' / 'default.yaml').exists() and (p / 'src').exists():\n",
    "            return p\n",
    "    for p in [Path.cwd(), *Path.cwd().parents]:\n",
    "        if (p / 'configs' / 'default.yaml').exists() and (p / 'src').exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "if repo_root is None:\n",
    "    if not REPO_URL:\n",
    "        raise RuntimeError('Repo not found. Set REPO_URL in this cell and rerun.')\n",
    "    if not REPO_DIR.exists():\n",
    "        subprocess.check_call(['git', 'clone', REPO_URL, str(REPO_DIR)])\n",
    "    repo_root = REPO_DIR\n",
    "\n",
    "%cd {repo_root}\n",
    "print('repo root:', Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, subprocess, sys\n",
    "from pathlib import Path\n",
    "\n",
    "if str(Path.cwd()) not in sys.path:\n",
    "    sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "def has(mod):\n",
    "    try:\n",
    "        importlib.import_module(mod)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "core_pkgs = [\n",
    "    ('numpy', 'numpy<2'),\n",
    "    ('scipy', 'scipy>=1.10'),\n",
    "    ('PIL', 'pillow>=9.5'),\n",
    "    ('sklearn', 'scikit-learn>=1.2'),\n",
    "    ('matplotlib', 'matplotlib>=3.7'),\n",
    "    ('tqdm', 'tqdm>=4.65'),\n",
    "    ('yaml', 'pyyaml>=6.0'),\n",
    "]\n",
    "missing = [req for mod, req in core_pkgs if not has(mod)]\n",
    "if missing:\n",
    "    print('Installing missing core packages:', missing)\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', *missing])\n",
    "else:\n",
    "    print('Core packages already installed')\n",
    "\n",
    "if not has('torch') or not has('torchvision'):\n",
    "    print('Installing torch/torchvision')\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'torch>=2.0', 'torchvision>=0.15'])\n",
    "else:\n",
    "    import torch, torchvision\n",
    "    print('torch:', torch.__version__, 'torchvision:', torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print('severstal exists:', os.path.exists('data/severstal'))\n",
    "print('neu exists:', os.path.exists('data/neu'))\n",
    "if not os.path.exists('data/severstal'):\n",
    "    raise RuntimeError('Missing data/severstal')\n",
    "if not os.path.exists('data/neu'):\n",
    "    raise RuntimeError('Missing data/neu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force GPU in a Colab-safe copied config\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "base_cfg = Path('configs/default.yaml')\n",
    "cfg = yaml.safe_load(base_cfg.read_text())\n",
    "cfg['device'] = 'cuda'\n",
    "colab_cfg = Path('configs/default.colab.yaml')\n",
    "colab_cfg.write_text(yaml.safe_dump(cfg, sort_keys=False))\n",
    "print('wrote', colab_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines.notebook_entrypoints import run_two_stage_stage1\n",
    "run_two_stage_stage1('configs/default.colab.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines.notebook_entrypoints import run_split_pipeline\n",
    "run_split_pipeline('configs/neu_split_a.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines.notebook_entrypoints import run_split_pipeline\n",
    "run_split_pipeline('configs/neu_split_b.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines.notebook_entrypoints import run_split_pipeline\n",
    "run_split_pipeline('configs/neu_split_c.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "for split in ['split_a', 'split_b', 'split_c']:\n",
    "    p = Path('outputs') / split / 'cascade' / 'metrics.json'\n",
    "    if not p.exists():\n",
    "        print(split, 'missing metrics')\n",
    "        continue\n",
    "    m = json.loads(p.read_text())\n",
    "    print(split, {\n",
    "        'tpr_unknown_system': m.get('tpr_unknown_system'),\n",
    "        'fpr_known_system': m.get('fpr_known_system'),\n",
    "        'stage1_pass_rate_known': m.get('stage1_pass_rate_known'),\n",
    "        'stage1_pass_rate_unknown': m.get('stage1_pass_rate_unknown'),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: persist outputs to Drive\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "dst = Path('/content/drive/MyDrive/fyp_outputs')\n",
    "if dst.parent.exists():\n",
    "    dst.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copytree('outputs', dst / 'outputs_latest', dirs_exist_ok=True)\n",
    "    print('saved outputs to', dst / 'outputs_latest')\n",
    "else:\n",
    "    print('Drive not mounted; skipping copy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
