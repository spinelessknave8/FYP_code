{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c24435c",
   "metadata": {},
   "source": [
    "# Two-Stage OSR Runner (Colab / VS Code Colab Kernel)\n",
    "\n",
    "Pure-Python notebook cells (no `!` or `%` magics) to avoid syntax issues in VS Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e80f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess,torch\n",
    "\n",
    "print(\"python:\", sys.executable)\n",
    "print(\"cwd:\", os.getcwd())\n",
    "\n",
    "try:\n",
    "    subprocess.run([\"nvidia-smi\"], check=False)\n",
    "except FileNotFoundError:\n",
    "    print(\"nvidia-smi not found; checking torch CUDA ...\")\n",
    "try:\n",
    "    print(\"torch:\", torch.__version__)\n",
    "    print(\"cuda available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"gpu count:\", torch.cuda.device_count())\n",
    "        print(\"gpu name:\", torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    print(\"torch check failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7620ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: mount Drive if running on Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print('Drive mounted')\n",
    "except Exception as e:\n",
    "    print('Drive mount skipped:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e965ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, subprocess\n",
    "\n",
    "REPO_URL = 'https://github.com/spinelessknave8/FYP_code.git'\n",
    "REPO_DIR = Path('/content/FYP-code')\n",
    "\n",
    "if not REPO_DIR.exists():\n",
    "    subprocess.check_call(['git', 'clone', REPO_URL, str(REPO_DIR)])\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "print('repo root:', Path.cwd())\n",
    "print('has config:', (Path('configs/default.yaml')).exists())\n",
    "print('has src:', (Path('src')).exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca6a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, subprocess, sys\n",
    "\n",
    "def has(mod):\n",
    "    try:\n",
    "        importlib.import_module(mod)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "core = [\n",
    "    ('numpy', 'numpy<2'),\n",
    "    ('scipy', 'scipy>=1.10'),\n",
    "    ('PIL', 'pillow>=9.5'),\n",
    "    ('sklearn', 'scikit-learn>=1.2'),\n",
    "    ('matplotlib', 'matplotlib>=3.7'),\n",
    "    ('tqdm', 'tqdm>=4.65'),\n",
    "    ('yaml', 'pyyaml>=6.0'),\n",
    "]\n",
    "missing = [req for mod, req in core if not has(mod)]\n",
    "if missing:\n",
    "    print('Installing missing core deps:', missing)\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', *missing])\n",
    "else:\n",
    "    print('Core deps already available')\n",
    "\n",
    "if not has('torch') or not has('torchvision'):\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'torch>=2.0', 'torchvision>=0.15'])\n",
    "\n",
    "import torch, torchvision\n",
    "print('torch:', torch.__version__, 'torchvision:', torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5d510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "sev = Path(\"/content/drive/MyDrive/datasets/severstal\")\n",
    "neu = Path(\"/content/drive/MyDrive/datasets/neu\")\n",
    "\n",
    "print(\"severstal drive path exists:\", sev.exists())\n",
    "print(\"neu drive path exists:\", neu.exists())\n",
    "\n",
    "if not sev.exists() or not neu.exists():\n",
    "    raise RuntimeError(\"Drive datasets not found at /content/drive/MyDrive/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "859d2de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: force GPU in temporary config copy\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "cfg = yaml.safe_load(Path('configs/default.yaml').read_text())\n",
    "cfg['device'] = 'cuda'\n",
    "Path('configs/default.colab.yaml').write_text(yaml.safe_dump(cfg, sort_keys=False))\n",
    "print('wrote configs/default.colab.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01049ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from src.pipelines.notebook_entrypoints import run_two_stage_stage1, run_split_pipeline\n",
    "\n",
    "t_all = time.time()\n",
    "print(\"[0/6] Building Colab config...\")\n",
    "\n",
    "cfg = yaml.safe_load(Path(\"configs/default.yaml\").read_text())\n",
    "cfg[\"device\"] = \"cuda\"\n",
    "cfg[\"severstal\"][\"data_root\"] = \"/content/drive/MyDrive/datasets/severstal\"\n",
    "cfg[\"severstal\"][\"train_csv\"] = \"train.csv\"\n",
    "cfg[\"severstal\"][\"images_dir\"] = \"train_images\"\n",
    "cfg[\"neu\"][\"data_root\"] = \"/content/drive/MyDrive/datasets/neu\"\n",
    "\n",
    "Path(\"configs/default.colab.yaml\").write_text(yaml.safe_dump(cfg, sort_keys=False))\n",
    "print(\"  wrote configs/default.colab.yaml\")\n",
    "\n",
    "print(\"[1/6] Running sanity checks...\")\n",
    "assert Path(\"/content/drive/MyDrive/datasets/severstal/train.csv\").exists(), \"Missing Severstal train.csv\"\n",
    "assert Path(\"/content/drive/MyDrive/datasets/severstal/train_images\").exists(), \"Missing Severstal train_images/\"\n",
    "assert Path(\"/content/drive/MyDrive/datasets/neu\").exists(), \"Missing NEU dataset folder\"\n",
    "print(\"  sanity checks passed\")\n",
    "\n",
    "print(\"[2/6] Stage 1: PatchCore training/calibration\")\n",
    "t = time.time()\n",
    "run_two_stage_stage1(\"configs/default.colab.yaml\")\n",
    "print(f\"  stage 1 done in {time.time() - t:.1f}s\")\n",
    "\n",
    "for i, split in enumerate([\"configs/neu_split_a.yaml\", \"configs/neu_split_b.yaml\", \"configs/neu_split_c.yaml\"], start=3):\n",
    "    print(f\"[{i}/6] Split pipeline: {split}\")\n",
    "    t = time.time()\n",
    "    run_split_pipeline(split)\n",
    "    print(f\"  {split} done in {time.time() - t:.1f}s\")\n",
    "\n",
    "print(f\"[6/6] All done in {time.time() - t_all:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "for split in ['split_a', 'split_b', 'split_c']:\n",
    "    p = Path('outputs') / split / 'cascade' / 'metrics.json'\n",
    "    if not p.exists():\n",
    "        print(split, 'missing metrics')\n",
    "        continue\n",
    "    m = json.loads(p.read_text())\n",
    "    print(split, {\n",
    "        'tpr_unknown_system': m.get('tpr_unknown_system'),\n",
    "        'fpr_known_system': m.get('fpr_known_system'),\n",
    "        'stage1_pass_rate_known': m.get('stage1_pass_rate_known'),\n",
    "        'stage1_pass_rate_unknown': m.get('stage1_pass_rate_unknown'),\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
